[path]
;root_path= D:\marwan\MSc\TNBC-Subtype\cassino\segmentation_performance\
;img_root_path=D:\marwan\MSc\TNBC-Subtype\cassino\segmentation_performance\
root_path=/home/marwan/TNBC-Subtype/cassino/medical_image_segmentation/
img_root_path=/home/joaquin/maia_pro/database/ddsm/

fold=0
#training on linux machine
linux=True
linux_gpu_id=1

#experiment name and model name for saving weights
exp=TNBC/baseline
model_name=baseline_resnet34

load_model=0
;model_path=../model/FETA/mean_teacher_labeled/baseline_resnet34/1649176592/epoch_33_val_dice_0.6688.pth
;model_path=../model/FETA/baseline_labeled/baseline_resnet34/lovely_supervised/epoch_21_val_dice_0.634.pth
;model_path=../model/FETA\baseline_labeled\baseline_resnet34\1649947523\baseline_resnet34_best_model.pth

[network]
#Architecture
backbone=resnet34

#Network input/output
patch_size=[256,256]
#multi_class=False means it is a multi-label problem
multi_class=True

num_classes=2
in_channels=1


#batch size for train/val
batch_size=16
labelled_bs=16
val_batch_size=1
num_workers=2

#Training Hyperparameters
max_iterations=6000
#optim can be adam or sgd with learning rate decay
optim=adam
base_lr=0.0003

deterministic=1
seed=1337

mean_teacher_epoch=10


# costs
ema_decay=0.99
consistency_type=mse
consistency=5
consistency_rampup=200.0
x=resnext101_32x8d
